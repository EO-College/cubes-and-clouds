{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83931476-0d6f-4d0f-a330-c345d47f9459",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/EO-College/cubes-and-clouds/main/icons/cnc_3icons_process_circle.svg\"\n",
    "     alt=\"Cubes & Clouds logo\"\n",
    "     style=\"float: center; margin-right: 10px; margin-left: 10px; max-height: 250px;\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6aed2f-1493-4636-a124-03c81b28bc52",
   "metadata": {},
   "source": [
    "# 3.2 Validation of the results with Pangeo\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pangeo-data/pangeo.io/refs/heads/main/public/Pangeo-assets/pangeo_logo.png\"\n",
    "     alt=\"Pangeo logo\"\n",
    "     style=\"float: center; margin-right: 10px; max-height: 80px;\"/>\n",
    "     \n",
    "In this exercise, we focus on the validation of the results we have produced when using the Pangeo ecosystem. In general, the accuracy of a satellite derived product is expressed by comparing it to in-situ measurements. Furthermore, we will compare the resulting snow cover time series to the runoff of the catchment to check the plausibility of the observed relationship.\n",
    "\n",
    "The steps involved in this analysis:\n",
    "- Generate Datacube time-series of snowmap,\n",
    "- Load _in-situ_ datasets: snow depth station measurements,\n",
    "- Pre-process and filter _in-situ_ datasets to match area of interest, \n",
    "- Perform validation of snow-depth measurements,\n",
    "- Plausibility check with runoff of the catchment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca425653-a63a-4090-9eab-bba515474133",
   "metadata": {},
   "source": [
    "Start by creating the folders and data files needed to complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19530f-6aa9-4cfa-be7d-d8791ae014b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ${DATA_PATH%/*/*}/notebooks/cubes-and-clouds/lectures/3.2_validation/exercises/32_data $HOME/\n",
    "!cp -r ${DATA_PATH%/*/*}/notebooks/cubes-and-clouds/lectures/3.2_validation/exercises/_32_pangeo_utilities.py $HOME/\n",
    "!mkdir -p $HOME/32_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4cb92-ac45-4e98-8d61-b2ff43c7dc84",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf270c-d73e-4109-854c-3cf36a1b36d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "from _32_pangeo_utilities import ( calculate_sca,\n",
    "                                 station_temporal_filter,\n",
    "                                 station_spatial_filter,\n",
    "                                 binarize_snow,\n",
    "                                 assign_site_snow,\n",
    "                                 validation_metrics)\n",
    "import os\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb40bc5-8916-4989-b026-1b354a33e695",
   "metadata": {},
   "source": [
    "## Region of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47820208-433d-4acb-9b97-4ef5ccda3feb",
   "metadata": {},
   "source": [
    "Load the Val Passiria Catchment, our region of interest. And plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69c8d6-62dc-474e-be39-3e5ca9c5daca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_outline = gpd.read_file('32_data/catchment_outline.geojson', crs=\"EPGS:4326\")\n",
    "catchment_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ca4a2-d012-44e1-96cb-d604ec04b463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "center_loc = catchment_outline.to_crs('+proj=cea').centroid.to_crs(epsg=\"4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6becaa-d39b-4303-a0f7-4ecb74ace486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OpenStreetMap\n",
    "map = folium.Map(location=[float(center_loc.y.iloc[0]), float(center_loc.x.iloc[0])], tiles=\"OpenStreetMap\", zoom_start=9)\n",
    "geo_j = catchment_outline[\"geometry\"].to_json()\n",
    "geo_j = folium.GeoJson(data=geo_j, style_function=lambda x: {\"fillColor\": \"orange\"})\n",
    "geo_j.add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d24033-7c7f-41fa-ad68-7c32b01f0a30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Datacube of Snowmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e399f-0c77-47d5-bc67-648fcf7cb048",
   "metadata": {},
   "source": [
    "We have prepared the workflow to generate the snow map as a python function `calculate_sca()`. The `calculate_sca()` is from `_32_pangeo_utilities` and is used to reproduce the snow map process graph using the Pangeo software stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5343f82-547c-4af5-8aaf-6188a0dba977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = \"2018-02-01\"\n",
    "end_date = \"2018-06-30\"\n",
    "bbox = tuple(catchment_outline.bounds.iloc[0])\n",
    "temporal_extent = [start_date, end_date]\n",
    "snow_map_cloud_free = calculate_sca(bbox, temporal_extent)\n",
    "snow_map_cloud_free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079721a-1c43-4956-8a15-f76a76d9c933",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load snow-station in-situ data\n",
    "Load the _in-situ_ datasets, snow depth station measurements. They have been compiled in the ClirSnow project and are available here: [Snow Cover in the European Alps](https://zenodo.org/record/5109574) with stations in our area of interest. \n",
    "\n",
    "We have made the data available for you already. We can load it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83229e1-dba8-4fd5-bd7c-b40ec401900e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load snow station datasets from zenodo:: https://zenodo.org/record/5109574\n",
    "station_df = pd.read_csv(\"32_data/data_daily_IT_BZ.csv\", parse_dates=[\"Date\"], date_format=\"%d.%m.%y\")\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cd8c1-371b-4010-94a0-c5020bf62d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load additional metadata for acessing the station geometries\n",
    "station_df_meta = pd.read_csv(\"32_data/meta_all.csv\")\n",
    "station_df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a09085-ba4c-497c-b710-404945865f62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-process and filter _in-situ_ snow station measurements\n",
    "\n",
    "### Filter Temporally\n",
    "Filter the in-situ datasets to match the snow-map time series using the function `station_temporal_filter()` from `_32_pangeo_utilities.py`, which merges the station dataframe with additional metadata needed for the Lat/Long information and convert them to geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7940eb6-4ff6-4d76-83ba-e8e68a68daf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snow_stations = station_temporal_filter(station_daily_df = station_df, \n",
    "                                        station_meta_df = station_df_meta,\n",
    "                                        start_date = start_date,\n",
    "                                        end_date = end_date)\n",
    "snow_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc8c3-ae2e-461b-87f8-e6e3b4d81df7",
   "metadata": {},
   "source": [
    "### Filter Spatially\n",
    "Filter the in-situ datasets into the catchment area of interest using `station_spatial_filter()` from `cubes_utilities.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8cbb1-990c-41d5-b25c-e1e57f71a9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations = station_spatial_filter(snow_stations, catchment_outline)\n",
    "catchment_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c78ce7-e5bf-4b31-abcd-20bd1fa65ef5",
   "metadata": {},
   "source": [
    "### Plot the filtered stations\n",
    "Visualize location of snow stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda36f9a-4c0a-4b17-b51c-26d4d31bcabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"There are\", len(np.unique(catchment_stations.Name)), \"unique stations within our catchment area of interest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ca23c-3c4a-43ce-b175-630dc1e6f87f",
   "metadata": {},
   "source": [
    "**_Quick Hint: Remember the number of stations within the catchment for the final quiz exercise_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70832a9b-a1bb-4703-8643-dd3c7ab3b6d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert snow depth to snow presence\n",
    "The stations are measuring snow depth. We only need the binary information on the presence of snow (yes, no). We use the `binarize_snow()`  function from `cubes_utilities.py` to assign 0 for now snow and 1 for snow in the **snow_presence** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0d8d2-f2e0-4392-be2f-02918c39977b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations = catchment_stations.assign(snow_presence=catchment_stations.apply(binarize_snow, axis=1))\n",
    "catchment_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ec45b-b0bf-4d46-af35-c524ce770903",
   "metadata": {},
   "source": [
    "### Save the pre-processed snow station measurements\n",
    "Save snow stations within catchment as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc1440-ce77-4c29-91f6-2bdace7f8c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"32_results/catchment_stations_pangeo.geojson\", \"w\") as file:\n",
    "    file.write(catchment_stations.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e38b03-2427-4718-8a11-544a6b0cc5aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract SCA from the data cube per station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a7f129-c2ba-4bf6-aadc-548394a0954c",
   "metadata": {},
   "source": [
    "### Prepare snow station data for usage in Pangeo\n",
    "Create a buffer of approximately 80 meters (0.00075 degrees) around snow stations and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40ffaa-f7af-4c12-87e2-b6dfdafe83ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd = gpd.read_file(\"32_results/catchment_stations_pangeo.geojson\")\n",
    "\n",
    "# OpenStreetMap\n",
    "map = folium.Map(location=[float(center_loc.y.iloc[0]), float(center_loc.x.iloc[0])], tiles=\"OpenStreetMap\", zoom_start=10)\n",
    "\n",
    "# catchment\n",
    "catchment_layer = folium.FeatureGroup(name=\"catchment\", show=True).add_to(map)\n",
    "folium.GeoJson(data=catchment_outline[\"geometry\"].to_json(), style_function=lambda x: {\"fillColor\": \"orange\"}).add_to(catchment_layer)\n",
    "\n",
    "# catchment stations\n",
    "stations_layer = folium.FeatureGroup(name=\"catchment stations\", show=True).add_to(map)\n",
    "\n",
    "for _, r in catchment_stations_gpd[[\"Longitude\", \"Latitude\"]].drop_duplicates().iterrows():\n",
    "    # Place the markers with the popup labels and data\n",
    "    folium.Marker(location=[r[\"Latitude\"], r[\"Longitude\"]],\n",
    "                  popup=\"Latitude: \" + str(r[\"Latitude\"]) \n",
    "                  + \"<br>\" \n",
    "                  + \"Longitude: \" + str(r[\"Longitude\"])\n",
    "                 ).add_to(stations_layer)\n",
    "    \n",
    "# catchment buffer\n",
    "buffer_layer = folium.FeatureGroup(name=\"catchment station buffer\", show=True).add_to(map)\n",
    "catchment_stations_gpd[\"geometry\"] = catchment_stations_gpd.geometry.buffer(0.00075)\n",
    "\n",
    "for _, r in catchment_stations_gpd[[\"geometry\"]].drop_duplicates().iterrows():\n",
    "    # Place the markers with the popup labels and data\n",
    "    folium.GeoJson(data=catchment_stations_gpd[\"geometry\"].to_json(), style_function=lambda x: {\"color\": \"#0F7229\", \"fillOpacity\": 0}).add_to(buffer_layer)\n",
    "\n",
    "\n",
    "folium.LayerControl().add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb83f8e-0ed5-4cc5-b870-ecb522e43f0c",
   "metadata": {},
   "source": [
    "Get the unique geometries for each catchment station buffer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1408a-7a7b-4e75-a81f-8d68249c4b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd.geometry.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3dc46f-a0bb-49d8-9610-0214dc602ea2",
   "metadata": {},
   "source": [
    "### Extract SCA from the data cube per station\n",
    "We extract the SCA value of our data cube at the buffered station locations. Therefore we use the process `aggregate_spatial()` with the aggregation method `median()`. This gives us the most common value in the buffer (snow or snowfree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8804e4-5ac2-47fc-8612-20b66eb411be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snow_map_cloud_free.rio.write_crs(\"EPSG:32632\", inplace=True)\n",
    "snow_map_cloud_free.rio.set_nodata(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1bcc3-81b3-436b-9d74-efcc1081c72b",
   "metadata": {},
   "source": [
    "### Reduce the amount of data by selecting a small Area Of Interest (AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38314524-82fb-4848-b86a-00af99f70a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd_utm32 = catchment_stations_gpd.to_crs(epsg=32632)\n",
    "minx, miny, maxx, maxy = catchment_stations_gpd_utm32[[\"geometry\"]].drop_duplicates().total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9708f7d-4025-42f0-bab6-af2b63113ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snowmap_clipped = snow_map_cloud_free.sel(x=slice(minx,maxx), y = slice(maxy, miny))\n",
    "snowmap_clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895d72f-2c06-489d-9ead-42c13bb010f5",
   "metadata": {},
   "source": [
    "### Aggregate to daily values\n",
    "Data aggregation is a very important step in the analysis. It allows to reduce the amount of data and to make the analysis more efficient. Moreover as in this case we are going to aggregate the date to daily values, this will allow use to compute statistic on the data at the basin scale later on.\n",
    "\n",
    "The `groupby` method allows to group the data by the time dimension, aggregating to the date and removing the time information, once the group is obtained we will aggregate the data by taking the max value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769ad0f-a278-412e-a943-a0845aaa5ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geoms = []\n",
    "for _, r in catchment_stations_gpd_utm32[[\"geometry\"]].drop_duplicates().iterrows():\n",
    "    geoms.append(r[\"geometry\"])\n",
    "\n",
    "snowmap_clipped = snow_map_cloud_free.rio.clip(geoms).groupby(snow_map_cloud_free.time.dt.floor('D')).max(dim=\"time\")\n",
    "snowmap_clipped = snowmap_clipped.rename({\"floor\":\"time\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8de284-7d72-4e5f-8a73-9dbbfaf5102f",
   "metadata": {},
   "source": [
    "It's time to persist the data in memory. We will use the persist method to load the data in memory and keep it there until the end of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4086be6-e906-4b44-af02-421035e20d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "snowmap_clipped.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70bd61-c865-4f97-bdbc-f3ca06de250c",
   "metadata": {},
   "source": [
    "### Extract SCA from the data cube per station\n",
    "We extract the SCA value of our data cube at the buffered station locations. Therefore we use the aggregation method `median()`. This gives us the most common value in the buffer (snow or snowfree).\n",
    "\n",
    "**Please note: this step may take around 5 minutes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232227f-2bae-41e9-8dcd-2230eb0c9866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x = []\n",
    "for _, r in catchment_stations_gpd_utm32[[\"geometry\"]].drop_duplicates().iterrows():\n",
    "    snowmap_station = snowmap_clipped.rio.clip([r[\"geometry\"]])\n",
    "    snowmap_station.persist()\n",
    "    median = snowmap_station.median([\"x\",\"y\"])\n",
    "    x.append(median.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359a85e-c25a-411d-b998-70a2b3a57186",
   "metadata": {
    "tags": []
   },
   "source": [
    "Save the values into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d0c17-7332-4ef6-b9ba-fa94ffc522e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(\"32_results/snowmap_pangeo/\"):\n",
    "    os.makedirs(\"32_results/snowmap_pangeo\")\n",
    "for idx,r in catchment_stations_gpd_utm32[[\"Name\"]].drop_duplicates().iterrows():\n",
    "    print(idx, r[\"Name\"])\n",
    "    x[idx].to_csv(\"32_results/snowmap_pangeo/\" + r[\"Name\"] + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b1d37-12b1-4967-b8d1-48685c6c5ae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combine station measurements and the extracted SCA from our data cube\n",
    "The **station measurements** are **daily** and all of the stations are combined in **one csv file**. \n",
    "The **extracted SCA values** are in the best case **six-daily** (Sentinel-2 repeat rate) and also all stations are in **one json file**.\n",
    "We will need to join the the extracted SCA with the station measurements by station (and time (selecting the corresponding time steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1260ef8-e005-4ac2-be10-1f1e3ab305ac",
   "metadata": {},
   "source": [
    "### Extract snow values from SCA extracted at the station location\n",
    "Let's have a look at the data structure first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a9ae00-db74-4a58-93a7-76fe5a833515",
   "metadata": {},
   "source": [
    "Open the snow covered area time series extracted at the stations. We'll have a look at it in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f68115-5578-478d-ada1-b9c3a41fbee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "for idx,r in catchment_stations_gpd[[\"Name\"]].drop_duplicates().iterrows():\n",
    "    print(idx, r[\"Name\"])\n",
    "    x.append(pd.read_csv(\"32_results/snowmap_pangeo/\" + r[\"Name\"] + \".csv\", parse_dates=[\"time\"], index_col=\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e9ea3-7e6d-4c63-b8de-bb940b1b3140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = x[0].index.tolist()\n",
    "snow_val_smartino = [y[0] for y in x[0].values]\n",
    "snow_val_rifiano = [y[0] for y in x[1].values]\n",
    "snow_val_plata = [y[0] for y in x[2].values]\n",
    "snow_val_sleonardo = [y[0] for y in x[3].values]\n",
    "snow_val_scena = [y[0] for y in x[4].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5779d4-de7e-4a27-ba3d-e7b3da396029",
   "metadata": {},
   "source": [
    "### Match in-situ measurements to dates in SCA \n",
    "Let's have a look at the in-situ measurement data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7b2a6-a63e-43a3-b8f5-661c61536391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd = gpd.read_file(\"32_results/catchment_stations_pangeo.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba03c5-22f0-4542-a559-0c2bb2d73539",
   "metadata": {
    "tags": []
   },
   "source": [
    "Convert column \"id\" from strings to dates to enable selection by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fc123-0099-4c34-af64-ecc893d6afac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd[\"id\"] = pd.to_datetime(catchment_stations_gpd[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69909e01-90ea-4f86-b4a0-2e46622d42e5",
   "metadata": {},
   "source": [
    "We are going to extract each station and keep only the dates that are available in the SCA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039220b-ad55-4d2f-9aad-33b5d523e1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd_smartino = catchment_stations_gpd.query(\"Name == 'S_Martino_in_Passiria_Osservatore'\")\n",
    "catchment_stations_gpd_smartino = catchment_stations_gpd_smartino[\n",
    "    catchment_stations_gpd_smartino.id.isin(dates)\n",
    "]\n",
    "\n",
    "catchment_stations_gpd_rifiano = catchment_stations_gpd.query(\"Name == 'Rifiano_Beobachter'\")\n",
    "catchment_stations_gpd_rifiano = catchment_stations_gpd_rifiano[\n",
    "    catchment_stations_gpd_rifiano.id.isin(dates)\n",
    "]\n",
    "\n",
    "catchment_stations_gpd_plata = catchment_stations_gpd.query(\"Name == 'Plata_Osservatore'\")\n",
    "catchment_stations_gpd_plata = catchment_stations_gpd_plata[\n",
    "    catchment_stations_gpd_plata.id.isin(dates)\n",
    "]\n",
    "\n",
    "catchment_stations_gpd_sleonardo = catchment_stations_gpd.query(\"Name == 'S_Leonardo_in_Passiria_Osservatore'\")\n",
    "catchment_stations_gpd_sleonardo = catchment_stations_gpd_sleonardo[\n",
    "    catchment_stations_gpd_sleonardo.id.isin(dates)\n",
    "]\n",
    "\n",
    "catchment_stations_gpd_scena = catchment_stations_gpd.query(\"Name == 'Scena_Osservatore'\")\n",
    "catchment_stations_gpd_scena = catchment_stations_gpd_scena[\n",
    "    catchment_stations_gpd_scena.id.isin(dates)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633819c-c9f0-4a28-9e33-9b68f92834b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combine in-situ measurements with SCA results at the stations \n",
    "The in situ measurements and the SCA are combined into one data set per station. This will be the basis for the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80657a7-1a50-404f-9f51-ab4787b4a4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smartino_snow = assign_site_snow(catchment_stations_gpd_smartino, snow_val_smartino)\n",
    "rifiano_snow = assign_site_snow(catchment_stations_gpd_rifiano, snow_val_rifiano)\n",
    "plata_snow = assign_site_snow(catchment_stations_gpd_plata, snow_val_plata)\n",
    "sleonardo_snow = assign_site_snow(catchment_stations_gpd_sleonardo, snow_val_sleonardo)\n",
    "scena_snow = assign_site_snow(catchment_stations_gpd_scena, snow_val_scena)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eaeefb-426b-4fa7-83f5-0067bbeb1107",
   "metadata": {},
   "source": [
    "Let's have a look at the SCA extracted at the station Plata Osservatore and it's in situ measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aede571-8e46-46c5-898e-d250634b055e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd_plata.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82995c3-ccd2-4a76-9cfa-0e149b3e03bc",
   "metadata": {},
   "source": [
    "Display snow presence threshold in in-situ data for Plata Osservatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7201df2-ebf0-4495-8bd9-6d0243349032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catchment_stations_gpd_plata.plot(x=\"id\", y=\"HS_after_gapfill\",rot=45,kind=\"line\",marker='o')\n",
    "plt.axhline(y = 0.4, color = \"r\", linestyle = \"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16752292-e134-4f28-b325-ead839532951",
   "metadata": {},
   "source": [
    "## Validate the SCA results with the snow station measurements \n",
    "Now that we have combined the SCA results with the snow station measurements we can start the actual validation. A **confusion matrix** compares the classes of the station data to the classes of the SCA result. The numbers can be used to calculate the accuracy (correctly classified cases / all cases).\n",
    "\n",
    "|             | no_snow | snow    |\n",
    "|-------------|---------|---------|\n",
    "| **no_snow** | correct | error   |\n",
    "| **snow**    | error   | correct |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fefa34-ae4d-4e43-985c-098ced246af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6438d-bf24-4b93-b684-901f6faf0e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "fig.suptitle(\"Error matrices for snow stations within our selected Catchment\")\n",
    "sns.heatmap(validation_metrics(smartino_snow)[1], annot=True, xticklabels=[\"No Snow\", \"Snow\"], yticklabels=[\"No Snow\", \"Snow\"], ax=ax1)\n",
    "ax1.set_title(\"San Martino in Passiria Osservatore\")\n",
    "ax1.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "\n",
    "\n",
    "sns.heatmap(validation_metrics(rifiano_snow)[1], annot=True, xticklabels=[\"No Snow\", \"Snow\"], yticklabels=[\"No Snow\", \"Snow\"], ax=ax2)\n",
    "ax2.set_title(\"Rifiano Beobachter\")\n",
    "ax2.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "\n",
    "\n",
    "sns.heatmap(validation_metrics(plata_snow)[1], annot=True, xticklabels=[\"No Snow\", \"Snow\"], yticklabels=[\"No Snow\", \"Snow\"], ax=ax3)\n",
    "ax3.set_title(\"Plata Osservatore\")\n",
    "ax3.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "\n",
    "\n",
    "sns.heatmap(validation_metrics(scena_snow)[1], annot=True, xticklabels=[\"No Snow\", \"Snow\"], yticklabels=[\"No Snow\", \"Snow\"], ax=ax4)\n",
    "ax4.set_title(\"Scena Osservatore\")\n",
    "ax4.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad0abc-1d43-4574-b6d8-916e45fbde61",
   "metadata": {},
   "source": [
    "The **accuracy** of the snow estimate from the satellite image computation for each station is shown below: \n",
    "\n",
    "\n",
    "| **On-site snow station**             | **Accuracy**|\n",
    "|--------------------------------------|-------------|\n",
    "| San Martino in Passiria Osservatore  | **100.00%** |\n",
    "| Rifiano Beobachter                   | **100.00%** |\n",
    "| Plata Osservatore                    |    92.3%   |\n",
    "| San Leonardo in Passiria Osservatore |    NaN      |\n",
    "| Scena Osservatore                    | **100.00%** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372191d3-ae11-4df6-abcd-f0bcb2fa3273",
   "metadata": {},
   "source": [
    "The fourth station **San Leonardo in Passiria Osservatore** recorded **_NaNs_** for snow depths for our selected dates, which could potentially be as a results of malfunctioning on-site equipments. Hence, we are not able to verify for it. But overall, the validation shows a 100% accuracy for stations **San Martino in Passiria Osservatore**, **Rifiano Beobachter** and **Scena Osservatore**, while station **Plata Osservatore** has False Positives decreasing the overall accuracy. This shows a good match between estimated snow values from satellite datasets and on-the ground measurements of the presence of snow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f454452-c2e7-4c0c-a8ab-260c7b0e48f0",
   "metadata": {},
   "source": [
    "## Compare to discharge data\n",
    "In addition to computing metrics for validating the data, we also check the plausibility of our results. We compare our results with another measure with a known relationship. In this case, we compare the **snow cover area** time series with the **discharge** time-series at the main outlet of the catchment. We suspect that after snow melting starts, with a temporal lag, the runoff will increase. Let's see if this holds true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2ddcd-7493-477a-8fcd-81ea3bc308a6",
   "metadata": {},
   "source": [
    "Load the discharge data at Meran, the main outlet of the catchment. We have prepared this data set for you, it's extracted from Eurac's [Environmental Data Platform Alpine Drought Observatory Discharge Hydrological Datasets](https://edp-portal.eurac.edu/discovery/9e195271-02ae-40be-b3a7-525f57f53c80)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc096eb8-b4d3-4056-9a1f-8c3921009f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discharge_ds = pd.read_csv('32_data/ADO_DSC_ITH1_0025.csv', \n",
    "                           sep=',', index_col='Time', parse_dates=True)\n",
    "discharge_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412118f-b9a3-4e00-811e-99ff77b85515",
   "metadata": {},
   "source": [
    "Load the SCA time series we have generated in a previous exercise. It's the time series of the aggregated snow cover area percentage for the whole catchment. **Please note: you need to complete the 3.1 exercise before proceeding!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e90d-95f7-4a5a-a298-22a58759e4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snow_perc_df = pd.read_csv(\"./31_results/filtered_snow_fraction_pangeo.csv\", \n",
    "                          sep=',', index_col='date', parse_dates=True)\n",
    "snow_perc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c88f7-f520-4889-a79e-731b5540e9ed",
   "metadata": {},
   "source": [
    "Let's plot the relationship between the snow covered area and the discharge in the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e61b7a-5db1-40ef-9fd5-db3896ac0faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_date = date(2018, 2, 1)\n",
    "end_date = date(2018, 6, 30)\n",
    "# filter discharge data to start and end dates\n",
    "discharge_ds = discharge_ds.loc[start_date:end_date]\n",
    "\n",
    "ax1 = discharge_ds.discharge_m3_s.plot(label='Discharge', xlabel='', ylabel='Discharge (m$^3$/s)')\n",
    "ax2 = snow_perc_df[\"SCA\"].plot(marker='o', secondary_y=True, label='SCA', xlabel='', ylabel='Snow cover area (%)')\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(0, 0.6))\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(0, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b8f01-5cff-4300-8c59-19f321458d38",
   "metadata": {},
   "source": [
    "The relationship looks as expected! Once the snow cover decreases the runoff increases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e970f-5e40-4e5e-ab8a-6c58f457890a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubes-and-clouds-pangeo",
   "language": "python",
   "name": "conda-env-cubes-and-clouds-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
