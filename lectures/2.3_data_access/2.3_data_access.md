# Access EO Data from the Cloud

Using a cloud provider for accessing data, and in this specific scenario Earth Observation data, could improve your productivity a lot. To get the most out of it, we will provide you some important insights.

## Learning objectives

- In this lecture you will learn the usage and peculiarities of the main data operators commonly available on cloud platforms like:
  - Data loading
  - Filter
  - Apply
  - Reduce
  - Resample
  - Aggregate
- Finally, you will be able to create a simple workflow with openEO or, alternatively with Pangeo.

The openEO exercises will use the openEO Python Client Side Processing functionality, which allows to experiment using openEO without a connection to an openEO back-end.
Additionally, we incorporated Pangeo exercises, which will allow you to experiment using the Pangeo ecosystem for scalable and interactive data analysis.

## Raster Data Loading

### Raster Data Loading with openEO

In openEO, your process graph will always start with defining the data you want to load, which can be done mainly using the following processes:

1. `load_collection`: loads a collection from the current back-end by its id and returns it as a processable data cube. The data that is added to the data cube can be restricted with the parameters spatial_extent, temporal_extent, bands and properties.
2. `load_stac`: loads data from a static STAC catalog or a STAC API Collection and returns the data as a processable data cube. A batch job result can be loaded by providing a reference to it. If supported by the underlying metadata and file format, the data that is added to the data cube can be restricted with the parameters spatial_extent, temporal_extent and bands.

[Exercise 2.3 Data Access Lazy Loading with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_lazy_loading.ipynb)

#### References

- [openEO Python Client Processing documentation](https://open-eo.github.io/openeo-python-client/cookbook/localprocessing.html)
- [load_collection process definition](https://processes.openeo.org/#load_collection)
- [load_stac process definition](https://processes.openeo.org/#load_stac)

### Raster Data Loading with Pangeo

With the Pangeo ecosystem, the STAC Catalogue Python Library `pystac_client` is recommended for lazily loading of data from a STAC Collection. To restrict the search, spatial extent can be passed as a parameter. Then for accessing the data, we use `stackstac` to create a data cube (an `xarray` in Python) of all the data.
 
[Exercise 2.3 Data Access Lazy Loading with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_lazy_loading.ipynb)

#### References

- [pystac_client](https://pystac-client.readthedocs.io/en/stable/)
- [stackstac](https://stackstac.readthedocs.io/en/latest/)
- [xarray](http://xarray-datatree.readthedocs.io)

## Processes on Datacubes

In the following part, the basic processes for manipulating datacubes are introduced.

### Filter

When filtering data, only the data that satisfies a condition is returned. For example, this condition could be a timestamp or interval, (a set of) coordinates, or specific bands. By applying filtering the datacube becomes smaller, according to the selected data.

With openEO, you can use [`filter_spatial`](https://processes.openeo.org/#filter_spatial), [`filter_temporal`](https://processes.openeo.org/#filter_temporal), [`filter_bands`](https://processes.openeo.org/#filter_bands).

Alternatively, using Pangeo, you can perform similar operations with tools like `xarray` and use Python’s `[]` syntax or `sel` or create masks with `where` for spatial, temporal, and band filtering, leveraging its powerful data processing capabilities of `xarray` Python package.

> :warning: Simplified
<span title="Filtering vegetarian options from [corn, potato, pig] returns [corn, potato].
">`filter([🌽, 🥔, 🐷], isVegetarian) => [🌽, 🥔]`</span>
>

In the image, the example datacube can be seen at the top with labeled dimensions. The filtering techniques are displayed separately below. On the left, the datacube is filtered temporally with the interval `["2020-10-15", "2020-10-27"]`. The result is a cube with only the rasters for the timestep that lies within that interval (`"2020-10-25"`) and unchanged bands and spatial dimensions. Likewise, the original cube is filtered for a specific band `["nir"]` in the middle and a specific spatial region `[Polygon(...)]` on the right.

![assets/dc_filter.png](assets/dc_filter.png "Datacube filtering: From the datacube 4 by 3 grid, arrows depict what happens if the grid is filtered. Temporal filtering results in data for one timestep with all four bands, filtering bands results in data with one band with all three timesteps, and spatial filtering results in all timesteps and bands being preserved, but all with a smaller area.")

> Figure: Datacube filtering: From the datacube 4 by 3 grid, arrows depict what happens if the grid is filtered. Temporal filtering results in data for one timestep with all four bands, filtering bands results in data with one band with all three timesteps, and spatial filtering results in all timesteps and bands being preserved, but all with a smaller area. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo - Indexing and selecting data with xarray](https://docs.xarray.dev/en/latest/user-guide/indexing.html).

Exercise 2.3 on Data Access Filter can be completed using both openEO and the Pangeo ecosystem:
- [Exercise 2.3 Data Access Filter with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_filter.ipynb)
- [Exercise 2.3 Data Access Filter with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_filter.ipynb)

### Apply

The `apply*` functions employ a process on the datacube that calculates new pixel values for each pixel, based on `n` other pixels. 

With openEO, the following `apply*` functions can be used: [`apply`](https://processes.openeo.org/#apply), [`apply_neighborhood`](https://processes.openeo.org/#apply_neighborhood), [`apply_dimension`](https://processes.openeo.org/#apply_dimension)).

Similarly, with Pangeo, the `apply` and `apply_ufunc` functions in `xarray` allow operations on multidimensional arrays, where new values are calculated for each element based on surrounding data, similar to the apply functions in openEO.

Please note that several programming languages use the name `map` instead of `apply`, but they describe the same type of function.

> :warning: Simplified
<span title="Applying the process 'cook' to [corn, potato, pig] returns [popcorn, fries, meat].">`apply([🌽, 🥔, 🐷], cook) => [🍿, 🍟, 🍖]`</span>
>

For the case `n = 1` this is called a unary function and means that only the pixel itself is considered when calculating the new pixel value. A prominent example is the `absolute()` function, calculating the absolute value of the input pixel value.

![./assets/dc_apply_unary.png](./assets/dc_apply_unary.png "Datacube apply unary: 3 example tiles hold values below and above 0. after applying the process 'absolute', all values in the three example tiles have changed to their absolute values above 0.")

> Figure: Datacube apply unary: 3 example tiles hold values below and above 0. after applying the process 'absolute', all values in the three example tiles have changed to their absolute values above 0. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo `xarray` with `apply_ufunc`](https://tutorial.xarray.dev/advanced/apply_ufunc/simple_numpy_apply_ufunc.html) and [Pangeo `xarray ` with `apply`](https://xarray.pydata.org/en/v0.12.3/generated/xarray.Dataset.apply.html).


If `n` is larger than 1, the function is called n-ary. In practice, this means that the pixel neighbourhood is taken into account to calculate the new pixel value. Such neighbourhoods can be of spatial and/or temporal nature. A spatial function works on a kernel that weights the surrounding pixels (e.g. smoothing values with nearby observations), a temporal function works on a time series at a certain pixel location (e.g. smoothing values over time). Combinations of types to n-dimensional neighbourhoods are also possible.

In the example below, an example weighted kernel with the openEO ecosystem (shown in the middle) is applied to the cube (via openEO [`apply_kernel`](https://processes.openeo.org/#apply_kernel)). To avoid edge effects (affecting pixels on the edge of the image with less neighbours), a padding has been added in the background.

![./assets/dc_apply_kernel.png](./assets/dc_apply_kernel.png "Datacube apply spatial kernel: Three example tiles hold some values with a lot of variance. A spatial kernel (a cell plus it's 4 direct neighbours) is applied to all pixels, and the result appears to be spatially smoothed, with less variance.")

> Figure: Datacube apply spatial kernel: Three example tiles hold some values with a lot of variance. A spatial kernel (a cell plus it's 4 direct neighbours) is applied to all pixels, and the result appears to be spatially smoothed, with less variance. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes)

Of course this also works for temporal neighbourhoods (timeseries), considering neighbours before and after a pixel. To be able to show the effect, two timesteps were added in this example figure. A moving average of window size 3 is then applied, meaning that for each pixel the average is calculated out of the previous, the next, and the timestep in question (t<sub>n-1</sub>, t<sub>n</sub> and t<sub>n+1</sub>). No padding was added which is why we observe edge effects (NA values are returned for t<sub>1</sub> and t<sub>5</sub>, because their temporal neighbourhood is missing input timesteps).

![./assets/dc_apply_ts.png](./assets/dc_apply_ts.png "Datacube apply temporal moving average: Smoothing is applied to 5 example tiles by calculating the mean of 3 timesteps of every single pixel. The resulting tiles for the timestamps look much more alike.")

> Figure: Datacube apply temporal moving average: Smoothing is applied to 5 example tiles by calculating the mean of 3 timesteps of every single pixel. The resulting tiles for the timestamps look much more alike. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo xarray rolling window](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.rolling.html).

Alternatively, a process can also be applied along a dimension of the datacube, meaning the input is no longer a neighbourhood of some sort but all pixels along that dimension (`n` equals the complete dimension). If a process is applied along the `time` dimension (e.g. a breakpoint detection), the complete pixel timeseries are the input. If a process is applied along the `spatial` dimensions (e.g. a `mean`), all pixels of an image are the input. The process is then applied to all pixels along that dimension and the dimension continues to exist. This is in contrast to [reduce](#reduce), which drops the specified dimension of the data cube. In the image below, a `mean` is applied to the `time` dimension. An example pixel timeseries is highlighted by a green line and processed step-by-step.

![./assets/dc_apply_dim_ts.png](./assets/dc_apply_dim_ts.png "Datacube apply dimension time: The mean of all 5 timesteps is calculated for every single pixel. The resulting 5 tiles look exaclty the same, as they have been averaged.")

> Figure: Datacube apply dimension time: The mean of all 5 timesteps is calculated for every single pixel. The resulting 5 tiles look exaclty the same, as they have been averaged. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes), [Pangeo xarray GroupBy: Group and Bin Data](https://docs.xarray.dev/en/stable/user-guide/groupby.html).

Try it out with the openEO and Pangeo ecosystems:

- [Exercise 2.3 Data Access Apply with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_apply.ipynb)
- [Exercise 2.3 Data Access Apply with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_apply.ipynb)

### Reduce

The [`reduce_dimension`](https://processes.openeo.org/#reduce_dimension) process _collapses_ a whole dimension of the datacube. It does so by using some sort of **reducer**, which is a function that calculates a single result from an amount of values, as e.g. `mean()`, `min()` and `max()` are. For example we can reduce the time dimension (`t`) of a timeseries by calculating the mean value of all timesteps for each pixel. We are left with a cube that has no time dimension, because all values of that dimension are compressed into a single mean value. The same goes for e.g. the spatial dimensions: If we calculate the mean along the `x` and `y` dimensions, we are left without any spatial dimensions, but a mean value for each instance that previously was a raster is returned. In the image below, the dimensions that are reduced are crossed out in the result.

> :warning: Simplified
<span title="Reducing [mixed greens, cucumber, tomato, onion] returns a salad.">`reduce([🥬, 🥒, 🍅, 🧅], prepare) => 🥗`</span>
>

Think of it as a waste press that does math instead of using brute force. Given a representation of our example datacube, let's see how it is affected.

![./assets/dc_reduce.png](./assets/dc_reduce.png "Datacube reduce: Three arrows depict what happens to the 12 example tiles, if they are reduced: Reducing timesteps leads to four tiles (one for each band), and the time dimension is deleted. Reducing bands lead to one tile per timestep, and the bands dimension is deleted. Reducing spatially leads to the original 4 by 3 bands by time layout, but the result has no spatial dimension and thus, the tiles have been turned into single values, per tile.")

> Figure: Datacube reduce: Three arrows depict what happens to the 12 example tiles, if they are reduced: Reducing timesteps leads to four tiles (one for each band), and the time dimension is deleted. Reducing bands lead to one tile per timestep, and the bands dimension is deleted. Reducing spatially leads to the original 4 by 3 bands by time layout, but the result has no spatial dimension and thus, the tiles have been turned into single values, per tile. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo xarray reduction](https://docs.xarray.dev/en/stable/user-guide/reshaping.html)

As mentioned earlier, reduction operations can be performed with both openEO and Pangeo:
- [Exercise 2.3 Data Access Reduce with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_reduce.ipynb)
- [Exercise 2.3 Data Access Reduce with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_reduce.ipynb)

### Resample

In a resampling processes, the _layout_ of a certain dimension is changed into another _layout_, most likely also changing the resolution of that dimension. This is done by mapping values of the source (old) datacube to the new layout of the target (new) datacube. During that process, resolutions can be _upscaled_ or _downscaled_ (also called _upsampling_ and _downsampling_), depending on whether they have a finer or a coarser spacing afterwards. A function is then needed to translate the existing data into the new resolution. A prominent example is to reproject a datacube into the coordinate reference system of another datacube, for example in order to merge the two cubes.

With the openEO ecosystem, you can use [`resample_cube_spatial`](https://processes.openeo.org/#resample_cube_spatial), [`resample_cube_temporal`](https://processes.openeo.org/#resample_cube_temporal)).
With the Pangeo ecosystem and `xarray`, you can use [`resample`](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.resample.html) or [`coarsen`](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.coarsen.html) 


> :warning: Simplified
<span title="Downscaling a raster image (to infinity) returns one pixel.">`resample(🖼️, downscale) => 🟦`</span>

<span title="Reprojecting a globe results into a map.">`resample(🌍, reproject) => 🗺️`</span>
>

The first figure gives an overview of temporal resampling. How exactly the input timesteps are rescaled to the output timesteps depends on the resampling function.

![./assets/dc_resample_time.png](./assets/dc_resample_time.png "Datacube temporal resampling (up and down): Downsampling: To a timeline-representation of the example tiles, another timeline with only 2 steps at different dates is applied. The result has tiles only at those new timesteps. In Upsampling, the existing 3 timesteps are sampled into 5 result timesteps.")

> Figure: Datacube temporal resampling (up and down): Downsampling: To a timeline-representation of the example tiles, another timeline with only 2 steps at different dates is applied. The result has tiles only at those new timesteps. In Upsampling, the existing 3 timesteps are sampled into 5 result timesteps. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Xarray Interpolation, Groupby, Resample, Rolling and Coarsen](https://earth-env-data-science.github.io/lectures/xarray/xarray-part2.html).

The second figure displays spatial resampling. Observe how in the upsampling process, the output datacube has not gained in information value. The resulting grid still carries the same pixel information, but in higher spatial resolution. Other upsampling methods may yield smoother results, e.g. by using interpolation.

![./assets/dc_resample_space.png](./assets/dc_resample_space.png "Datacube spatial resampling (up and down): Downsampling: The resulting tiles have a lower spatial resolution than the input tiles. Upsampling: The resulting tiles have a higher spatial resolution than the input tiles, but contain the same image than before (no information added).")

> Figure: Datacube spatial resampling (up and down): Downsampling: The resulting tiles have a lower spatial resolution than the input tiles. Upsampling: The resulting tiles have a higher spatial resolution than the input tiles, but contain the same image than before (no information added). Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo `xarray` coarsen](https://earth-env-data-science.github.io/lectures/xarray/xarray-part2.html#coarsen).

Try it out with exercises using both the openEO and Pangeo ecosystems:
- [Exercise 2.3 Data Access Resample with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_resample.ipynb)
- [Exercise 2.3 Data Access Resample with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_resample.ipynb)

### Aggregate

An aggregation of a datacube can be thought of as a grouped reduce. That means it consists of two steps:

1. Grouping via a grouping variable, i.e. spatial geometries or temporal intervals
2. Reducing these groups along the grouped dimension with a certain reducer function, e.g. calculating the mean pixel value per polygon or the maximum pixel values per month

While the layout of the reduced dimension is changed, other dimensions keep their resolution and geometry. But in contrast to pure `reduce`, the dimensions along which the reducer function is applied still exist after the operation.

> :warning: Simplified
<span title="Aggregating different family representations with 3, 2 and 4 members with the function 'countFamilyMembers' returns [3, 2, 4].">`aggregate(👪 👩‍👦 👨‍👩‍👦‍👦, countFamilyMembers) => [3️⃣, 2️⃣, 4️⃣]`</span>
>

A temporal aggregation (e.g. with openEO [`aggregate_temporal`](https://processes.openeo.org/#aggregate_temporal) or with Pangeo [GroupBy](https://docs.xarray.dev/en/stable/user-guide/groupby.html]) is similar to the downsampling process, as it can be seen in the according image above. Intervals for grouping can either be set manually, or periods can be chosen: monthly, yearly, etc. All timesteps in an interval are then collapsed via a reducer function (`mean`, `max`, etc.) and assigned to the given new labels.

A spatial aggregation (e.g. with openEO [`aggregate_spatial`](https://processes.openeo.org/#aggregate_spatial) or with Pangeo [GroupBy](https://docs.xarray.dev/en/stable/user-guide/groupby.html]) works in a similar manner. Polygons, lines and points can be selected for grouping. Their spatial dimension is then reduced by a given process and thus, a vector cube is returned. The vector cube then has dimensions containing features, attributes and time. In the graphic below, the grouping is only shown for the first timestep.

![./assets/dc_aggregate_space.png](./assets/dc_aggregate_space.png "Datacube spatial aggregation: A line and a polygon are selected from the original example tiles. The pixels covered by these geometries are aggregated and the result consists no longer of imagery tiles but of an array with values for 2 geometries by 4 bands by 3 timesteps.")

> Figure: Datacube spatial aggregation: A line and a polygon are selected from the original example tiles. The pixels covered by these geometries are aggregated and the result consists no longer of imagery tiles but of an array with values for 2 geometries by 4 bands by 3 timesteps. Reference: [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes); [Pangeo `xarray` groupby](https://docs.xarray.dev/en/stable/user-guide/groupby.html).

Try it out with openEO and Pangeo:
- [Exercise 2.3 Data Access Aggregate with openEO](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/23_data_access_aggregate.ipynb)
- [Exercise 2.3 Data Access Aggregate with Pangeo](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/2.3_data_access/exercises/_alternatives/pangeo_data_access_aggregate.ipynb)

### Recap Processes
Here are some exercises to recap the different processes that can be used on a data cube.

<br>

<iframe src="https://create.eo-college.org/wp-admin/admin-ajax.php?action=h5p_embed&id=7" width="958" height="843" frameborder="0" allowfullscreen="allowfullscreen" title="Cubes&amp;Clouds: Find Data Cube Processes"></iframe><script src="https://create.eo-college.org/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script>

<br>

<iframe src="https://create.eo-college.org/wp-admin/admin-ajax.php?action=h5p_embed&id=9" width="958" height="1034" frameborder="0" allowfullscreen="allowfullscreen" title="Cubes&amp;Clouds: Data Cube Processes Crossword"></iframe><script src="https://create.eo-college.org/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script>

<br>

<iframe src="https://create.eo-college.org/wp-admin/admin-ajax.php?action=h5p_embed&id=8" width="958" height="801" frameborder="0" allowfullscreen="allowfullscreen" title="Cubes&amp;Clouds: Identify Data Cube Processes"></iframe><script src="https://create.eo-college.org/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script>

### References
- [openeo.org (2022). Processes on Datacubes.](https://openeo.org/documentation/1.0/datacubes.html#processes-on-datacubes)
- [pangeo.io (2022).](https://pangeo.io)
- [xarray (2022).](https://docs.xarray.dev)

## openEO - A standardized API for EO cloud processing

### The need for a standarized API in EO cloud processing

Earth Observation data are becoming too large to be downloaded locally for analysis. Also, the way they are organised (as tiles, or granules: files containing the imagery for a small part of the Earth and a single observation date) makes it unnecessary complicated to analyse them. The solution to this is to store these data in the cloud, on compute back-ends, process them there, and browse the results or download resulting figures or numbers. But how do we do that? openEO develops an open application programming interface (API) that connects clients like R, Python and JavaScript to big Earth observation cloud back-ends in a simple and unified way.
With such an API,

- each client can work with every back-end, and
- it becomes possible to compare back-ends in terms of capacity, cost, and results (validation, reproducibility)

### What does openEO stand for?

The acronym openEO contracts two concepts:

open: used here in the context of open source software; open source software is available in source code form, and can be freely modified and redistributed; the openEO project will create open source software, reusable under a liberal open source license (Apache 2.0)
EO: Earth observation
Jointly, the openEO targets the processing and analysis of Earth observation data. The main objectives of the project are the following concepts:

- Simplicity: nowadays, many end-users use Python or R to analyse data and JavaScript to develop web applications; analysing large amounts of EO imagery should be equally simple, and seamlessly integrate with existing workflows
- Unification: current EO cloud back-ends all have a different API (opens new window), making EO data analysis hard to validate and reproduce and back-ends difficult to compare in terms of capability and costs, or to combine them in a joint analysis across back-ends. A unified API can resolve many of these problems.

### Why an API?

An API is an application programming interface. It defines a language that two computers (a client and a server) use to communicate.
The following figure shows how many interfaces are needed to be able to compare back-ends from different clients, without an openEO API. And if you use the slider you will see how the situation becomes much clearer with a standardized API.

<iframe src="https://create.eo-college.org/wp-admin/admin-ajax.php?action=h5p_embed&id=6" width="958" height="564" frameborder="0" allowfullscreen="allowfullscreen" title="Cubes&amp;Clouds: openEO standardized processing in EO clouds"></iframe><script src="https://create.eo-college.org/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script>


[![openEO - A standardized API for EO cloud processing](https://img.youtube.com/vi/iBRL3yVmA2M/0.jpg)](https://youtu.be/iBRL3yVmA2M) <br>
> Video content in collaboration with [Edzer Pebesma](https://www.uni-muenster.de/Geoinformatics/institute/staff/index.php/119/edzer_pebesma) (University of Münster). <br>
> *"For analysing Earth Observation data, don't use a platform that locks you in."*

### References
- [openeo.org - About OpenEO](https://openeo.org/about.html#openeo)
- [Edzer Pebesma, Wolfgang Wagner, Jan Verbesselt, Erwin Goor, Christian Briese, Markus Neteler (2016). OpenEO: a GDAL for Earth Observation Analytics. https://r-spatial.org/2016/11/29/openeo.html](https://r-spatial.org/2016/11/29/openeo.html)
- [openeo.org - Project Deliverable 22](https://github.com/Open-EO/openeo-D22/tree/master)

## Pangeo - An Open-Source Ecosystem for Cloud-Based Data Analysis

### The need for a standarized API in EO cloud processing
Pangeo - An Open-Source Ecosystem for Cloud-Based Data Analysis
The need for an open-source ecosystem in cloud-based data analysis
Earth Observation data are growing rapidly in size, making it increasingly difficult to download and process them locally. Additionally, the way these data are structured—often as tiles or granules (files containing imagery for a specific part of the Earth and a single observation date)—can complicate analysis. The solution to this challenge is to store and process these data in the cloud, utilizing scalable compute resources, and to browse or download the processed results. But how do we achieve this? Pangeo is an open-source ecosystem that enables scalable analysis of large geospatial and environmental data in the cloud. It leverages Python and tools such as xarray, dask, and zarr to provide an accessible, flexible, and high-performance framework for data processing and analysis.

With this ecosystem:

- Users can seamlessly process and analyze large datasets in the cloud using powerful, distributed computing tools.
- It becomes easier to work with diverse data sources and compare different cloud platforms for performance, cost, and reproducibility of results.

### What does Pangeo stand for?
The acronym Pangeo combines two key concepts:

- **Pan**: Derived from the Greek word for "all" or "every," reflecting the goal of making tools and data accessible to everyone, with a focus on enabling large-scale data analysis and open collaboration. 
- **Geo**: Referring to geospatial and Earth system data, Pangeo focuses on the analysis and processing of large environmental datasets, particularly in the context of Earth Observation (EO), climate science, and related fields.

Together, Pangeo provides an open-source ecosystem for scalable analysis of geospatial and Earth system data in the cloud. The main objectives of the Pangeo project include:

- **Simplicity*: Pangeo leverages widely-used Python libraries like xarray, dask, and zarr to provide easy-to-use tools for processing and analyzing large, multidimensional datasets. The aim is to make working with large volumes of geospatial data as simple as possible, while integrating seamlessly into existing workflows.
- **Unification**: Different data sources and computing environments often require specific configurations and APIs, which can make it difficult to combine and compare datasets across platforms. Pangeo unifies these efforts by offering a set of open-source tools and a scalable framework that works across multiple cloud back-ends, promoting reproducibility, cost efficiency, and data interoperability.

### How is the API for Pangeo?

The Pangeo ecosystem doesn't have a single API, but instead relies on a set of Python tools for scalable data processing. Key components include:

- [xarray](https://docs.xarray.dev/en/stable/): For working with multi-dimensional arrays, such as geospatial data.
- |dask](https://www.dask.org): For distributed computing, enabling parallel processing of large datasets.
- [zarr](https://zarr.dev): A storage format for efficient handling of large, chunked datasets.

These tools work together to provide a flexible, cloud-based framework for Earth system data analysis.

### References
- [Pangeo.io - About the Pangeo ecosystem](https://www.pangeo.io)
- [xarray (2022).](https://docs.xarray.dev)

# Quiz

Loading: What is the difference between using an openEO remote back-end and openEO Python Client-Side-Processing? Tick what is correct. *Answer in exercises: 23_data_access_lazy_loading.ipynb and pangeo_data_access_lazy_loading.ipynb* 

    [[ ]] You need an account to authenticate in both cases
    [[x]] For openEO, you don't need an account with Client-Side Processing
    [[x]] For openEO, the client-side processing does not interact with an openEO back-end
    [[x]] data processing does not interact with a openEO back-end

Loading: What are the dimension names of the loaded datacube? *Answer in exercise: 23_data_access_lazy_loading.ipynb and pangeo_access_lazy_loading.pynb'*

    [( )] northing, easting, time, spectral
    [( )] lat, lon, t, bands
    [(x)] time, band, y, x

Filtering: How many time steps are left after filtering temporally 2022-05-10, 2022-06-30? *Answer in exercise: 23_data_access_filter.ipynb and pangeo_data_access_filter.ipynb*

    [( )] 11
    [(x)] 9
    [( )] 32

Filteringi with openEO: How many pixels are left along `y` after using `filter_bbox` with `spatial_extent = {"west": 11.259613, "east": 11.406212, "south": 46.461019, "north": 46.522237}`

? *Answer in exercise: 23_data_access_filter.ipynb and pangeo_data_access_filter.ipynb*

    [( )] 1006
    [( )] 1145
    [(x)] 489

Reducing Dimension: What would be a use case for reducing the time dimension? Tick what is correct.

    [[ ]] Get a full time series graph
    [[x]] Getting a cloudfree image for a certain time range
    [[x]] Get information about a whole sesaon
    [[ ]] Filling gaps in a time series

Reducing Bands: How many pixels are left in the datacube after we use `reduce_dimension` over band? *Answer in exercises: 
- 23_data_access_reduce.ipynb
- pangeo_data_access_reduce.ipynb

    [[21226010]]

Reducing Dimension: What are the dimension names after running `reduce_spatial` (or `where` for Python `xarray` users? *Answer in exercise: 23_data_access_reduce.ipynb and pangeo_data_access_reduce.iynb*

    [( )] x, y, band
    [( )] time, x, y
    [(x)] time, band
